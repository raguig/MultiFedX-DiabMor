{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7380b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete - data loaded, model defined.\n",
      "Pre-train Epoch 1: Loss 0.6526\n",
      "Pre-train Epoch 2: Loss 0.6416\n",
      "Pre-train Epoch 3: Loss 0.6334\n",
      "Pre-train Epoch 4: Loss 0.6122\n",
      "Pre-train Epoch 5: Loss 0.5863\n",
      "Pre-trained global model ready. Initial parameters extracted.\n",
      "Number of parameter tensors: 6\n"
     ]
    }
   ],
   "source": [
    "# Cell 0: Import libraries & define model class\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define model class FIRST\n",
    "class DiabetesNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(8, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/diabetes.csv')\n",
    "X = df.drop('Outcome', axis=1).values\n",
    "y = df['Outcome'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "test_ds = TensorDataset(X_test_t, y_test_t)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Setup complete - data loaded, model defined.\")\n",
    "\n",
    "# Now pre-train global model\n",
    "global_model = DiabetesNet()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(global_model.parameters(), lr=0.001)\n",
    "\n",
    "train_ds_global = TensorDataset(torch.tensor(X_train, dtype=torch.float32), \n",
    "                                torch.tensor(y_train, dtype=torch.float32).unsqueeze(1))\n",
    "train_loader_global = DataLoader(train_ds_global, batch_size=32, shuffle=True)\n",
    "\n",
    "epochs =12\n",
    "for epoch in range(epochs):\n",
    "    global_model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader_global:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = global_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Pre-train Epoch {epoch+1}: Loss {running_loss / len(train_loader_global):.4f}\")\n",
    "\n",
    "# Extract initial parameters\n",
    "initial_parameters = [p.detach().cpu().numpy() for p in global_model.parameters()]\n",
    "\n",
    "print(\"Pre-trained global model ready. Initial parameters extracted.\")\n",
    "print(f\"Number of parameter tensors: {len(initial_parameters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3182268c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete - data loaded, model defined.\n"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "# Reload your data and scaler if needed (copy from previous notebook)\n",
    "df = pd.read_csv('../data/diabetes.csv')\n",
    "X = df.drop('Outcome', axis=1).values\n",
    "y = df['Outcome'].values\n",
    "\n",
    "# Assuming you already have scaler from baseline\n",
    "# If not, re-fit it here:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit on full X for consistency (or just train part)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Use your previous train/test split (or re-create for reproducibility)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "test_ds = TensorDataset(X_test_t, y_test_t)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "# Your model class (copy from baseline)\n",
    "class DiabetesNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(8, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "print(\"Setup complete - data loaded, model defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fb5756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameters(net: nn.Module, parameters: List[np.ndarray]):\n",
    "    \"\"\"Load numpy parameters into model state_dict\"\"\"\n",
    "    if not parameters:\n",
    "        print(\"Warning: Empty parameters received - skipping load\")\n",
    "        return\n",
    "    \n",
    "    state_dict = net.state_dict()\n",
    "    params_dict = zip(state_dict.keys(), parameters)\n",
    "    \n",
    "    for key, param in params_dict:\n",
    "        state_dict[key] = torch.from_numpy(param).float()\n",
    "    \n",
    "    net.load_state_dict(state_dict, strict=True)  # Changed to strict=True\n",
    "    print(f\"[DEBUG] Parameters loaded into model\")\n",
    "\n",
    "def get_parameters(net: nn.Module) -> List[np.ndarray]:\n",
    "    \"\"\"Extract parameters as numpy arrays\"\"\"\n",
    "    params = [val.cpu().detach().numpy() for val in net.parameters()]\n",
    "    print(f\"[DEBUG] Extracted {len(params)} parameter tensors\")\n",
    "    return params\n",
    "\n",
    "def train_local(net: nn.Module, trainloader: DataLoader, epochs: int = 1, device: str = \"cpu\"):\n",
    "    \"\"\"Train model locally and return number of samples trained\"\"\"\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    \n",
    "    total_samples = 0\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for data, target in trainloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * target.size(0)\n",
    "            total_samples += target.size(0)\n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / len(trainloader.dataset)\n",
    "        print(f\"  Local training epoch loss: {avg_epoch_loss:.4f}\")\n",
    "    \n",
    "    return total_samples\n",
    "\n",
    "def evaluate_local(net: nn.Module, testloader: DataLoader, device: str = \"cpu\"):\n",
    "    criterion = nn.BCELoss()\n",
    "    loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = net(data)\n",
    "            loss += criterion(output, target).item() * target.size(0)\n",
    "            pred = (output > 0.5).float()\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            total += target.size(0)\n",
    "    loss /= total\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid: str, net: nn.Module, trainloader: DataLoader, valloader: DataLoader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        try:\n",
    "            return get_parameters(self.net)\n",
    "        except Exception as e:\n",
    "            print(f\"Client {self.cid} failed get_parameters: {e}\")\n",
    "            raise\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"\\n[Client {self.cid}] fit() called with {len(parameters)} params\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        \n",
    "        # Get params before training\n",
    "        before_params = [p.detach().cpu().numpy().copy() for p in self.net.parameters()]\n",
    "        \n",
    "        num_samples = train_local(self.net, self.trainloader, epochs=12)\n",
    "        \n",
    "        # Get params after training\n",
    "        after_params = get_parameters(self.net)\n",
    "        \n",
    "        # Check if params changed\n",
    "        param_changed = False\n",
    "        for i, (before, after) in enumerate(zip(before_params, after_params)):\n",
    "            if not np.allclose(before, after):\n",
    "                param_changed = True\n",
    "                print(f\"[Client {self.cid}] Parameter {i} changed: max diff = {np.max(np.abs(before - after)):.6f}\")\n",
    "        \n",
    "        if not param_changed:\n",
    "            print(f\"[Client {self.cid}] WARNING: No parameters changed during training!\")\n",
    "        \n",
    "        print(f\"[Client {self.cid}] fit() returning {num_samples} samples trained\")\n",
    "        return get_parameters(self.net), num_samples, {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = evaluate_local(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader.dataset), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "# Updated client_fn with proper context handling\n",
    "from flwr.common import Context\n",
    "\n",
    "def client_fn(context: Context) -> fl.client.Client:\n",
    "    \"\"\"Flower client constructor - creates a new client per partition\"\"\"\n",
    "    # Extract client ID - try multiple approaches for compatibility\n",
    "    try:\n",
    "        cid = str(context.client_id)\n",
    "    except:\n",
    "        try:\n",
    "            cid = str(context.node_config.get(\"partition-id\", 0))\n",
    "        except:\n",
    "            cid = \"0\"\n",
    "    \n",
    "    cid_int = int(cid) if cid.isdigit() else 0\n",
    "    \n",
    "    # Ensure cid_int is within valid range\n",
    "    if cid_int >= NUM_CLIENTS:\n",
    "        cid_int = cid_int % NUM_CLIENTS\n",
    "    \n",
    "    print(f\"Creating client {cid_int} with {len(trainloaders[cid_int].dataset)} train samples\")\n",
    "    \n",
    "    # Create fresh model and client for this partition\n",
    "    net = DiabetesNet()\n",
    "    client = DiabetesClient(\n",
    "        cid=str(cid_int),\n",
    "        net=net,\n",
    "        trainloader=trainloaders[cid_int],\n",
    "        valloader=valloaders[cid_int]\n",
    "    )\n",
    "    return client.to_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7a66423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: train samples=49, val samples=13, pos class in train: 38.78%\n",
      "Client 1: train samples=49, val samples=13, pos class in train: 36.73%\n",
      "Client 2: train samples=49, val samples=13, pos class in train: 30.61%\n",
      "Client 3: train samples=49, val samples=13, pos class in train: 34.69%\n",
      "Client 4: train samples=48, val samples=13, pos class in train: 35.42%\n",
      "Client 5: train samples=48, val samples=13, pos class in train: 39.58%\n",
      "Client 6: train samples=48, val samples=13, pos class in train: 37.50%\n",
      "Client 7: train samples=48, val samples=13, pos class in train: 41.67%\n",
      "Client 8: train samples=48, val samples=13, pos class in train: 37.50%\n",
      "Client 9: train samples=48, val samples=13, pos class in train: 35.42%\n",
      "Created 10 clients with local train/val splits.\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 10\n",
    "\n",
    "# Split training data into NUM_CLIENTS parts (simulate different clinics)\n",
    "X_train_splits = np.array_split(X_train, NUM_CLIENTS)\n",
    "y_train_splits = np.array_split(y_train, NUM_CLIENTS)\n",
    "\n",
    "trainloaders = []\n",
    "valloaders = []\n",
    "\n",
    "for i in range(NUM_CLIENTS):\n",
    "    # Safe split without stratify\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train_splits[i], y_train_splits[i],\n",
    "        test_size=0.2, \n",
    "        random_state=42 + i\n",
    "    )\n",
    "    \n",
    "    # Optional: print to debug\n",
    "    print(f\"Client {i}: train samples={len(y_tr)}, val samples={len(y_val)}, \"\n",
    "          f\"pos class in train: {np.mean(y_tr):.2%}\")\n",
    "    \n",
    "    train_ds = TensorDataset(torch.tensor(X_tr, dtype=torch.float32), \n",
    "                             torch.tensor(y_tr, dtype=torch.float32).unsqueeze(1))\n",
    "    val_ds   = TensorDataset(torch.tensor(X_val, dtype=torch.float32), \n",
    "                             torch.tensor(y_val, dtype=torch.float32).unsqueeze(1))\n",
    "    \n",
    "    trainloaders.append(DataLoader(train_ds, batch_size=16, shuffle=True))\n",
    "    valloaders.append(DataLoader(val_ds, batch_size=16, shuffle=False))\n",
    "\n",
    "print(f\"Created {NUM_CLIENTS} clients with local train/val splits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38f7f6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-07 16:51:19,658\tINFO worker.py:1850 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray initialized manually.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "ray.init(ignore_reinit_error=True, num_cpus=4)\n",
    "print(\"Ray initialized manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3516b324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flower version: 1.26.1\n"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "print(\"Flower version:\", fl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57735dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting federated simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-07 16:51:30,859\tINFO worker.py:2012 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'object_store_memory': 628235059.0, 'node:127.0.0.1': 1.0, 'memory': 1465881805.0, 'node:__internal_head__': 1.0, 'CPU': 4.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 0.0}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m Creating client 9 with 48 train samples\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [Client 9] fit() called with 6 params\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [DEBUG] Parameters loaded into model\n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=gcs_server)\u001b[0m [2026-02-07 16:51:56,509 E 25012 1368] (gcs_server.exe) gcs_server.cc:302: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m   Local training epoch loss: 0.5788\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m   Local training epoch loss: 0.5747\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m   Local training epoch loss: 0.5709\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m   Local training epoch loss: 0.5677\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m   Local training epoch loss: 0.5641\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [DEBUG] Extracted 6 parameter tensors\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [Client 9] Parameter 0 changed: max diff = 0.013801\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [Client 9] Parameter 1 changed: max diff = 0.013211\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [Client 9] Parameter 2 changed: max diff = 0.013880\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [Client 9] Parameter 3 changed: max diff = 0.012452\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [Client 9] Parameter 4 changed: max diff = 0.014357\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [Client 9] Parameter 5 changed: max diff = 0.000680\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [Client 9] fit() returning 240 samples trained\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [DEBUG] Extracted 6 parameter tensors\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m Creating client 9 with 48 train samples\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m [Client 7] fit() called with 6 params\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [DEBUG] Parameters loaded into model\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[33m(raylet)\u001b[0m [2026-02-07 16:52:04,961 E 3996 31056] (raylet.exe) main.cc:975: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m   Local training epoch loss: 0.5394\u001b[32m [repeated 215x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [DEBUG] Extracted 6 parameter tensors\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [Client 5] Parameter 5 changed: max diff = 0.007508\u001b[32m [repeated 252x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [Client 5] fit() returning 240 samples trained\u001b[32m [repeated 42x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 19.94s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.5224156111478806\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.5089602440595626\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.49736054241657257\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.4875556528568268\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.47851642668247224\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, np.float64(0.8)),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, np.float64(0.8)),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, np.float64(0.8076923076923078)),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, np.float64(0.8307692307692308)),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, np.float64(0.823076923076923))]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation finished.\n",
      "History distributed metrics: {'accuracy': [(1, np.float64(0.8)), (2, np.float64(0.8)), (3, np.float64(0.8076923076923078)), (4, np.float64(0.8307692307692308)), (5, np.float64(0.823076923076923))]}\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m Creating client 0 with 49 train samples\n",
      "\u001b[36m(ClientAppActor pid=14816)\u001b[0m [DEBUG] Parameters loaded into model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=22224)\u001b[0m [2026-02-07 16:52:19,638 E 22224 18804] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Define Client Function & Run Simulation (FIXED)\n",
    "\n",
    "# Strategy with explicit metric aggregation\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,\n",
    "    fraction_evaluate=1.0,\n",
    "    min_fit_clients=NUM_CLIENTS,\n",
    "    min_evaluate_clients=NUM_CLIENTS,\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(initial_parameters),\n",
    "    evaluate_metrics_aggregation_fn=lambda results: {\n",
    "        \"accuracy\": np.mean([r[\"accuracy\"] for _, r in results]) if results else 0.0\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Starting federated simulation...\")\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=5),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 2, \"num_gpus\": 0.0},  # Increased CPU resources\n",
    ")\n",
    "\n",
    "print(\"Simulation finished.\")\n",
    "if hasattr(history, 'metrics_distributed'):\n",
    "    print(\"History distributed metrics:\", history.metrics_distributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1aa78ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation History:\n",
      "History (loss, distributed):\n",
      "\tround 1: 0.5224156111478806\n",
      "\tround 2: 0.5089602440595626\n",
      "\tround 3: 0.49736054241657257\n",
      "\tround 4: 0.4875556528568268\n",
      "\tround 5: 0.47851642668247224\n",
      "History (metrics, distributed, evaluate):\n",
      "{'accuracy': [(1, np.float64(0.8)),\n",
      "              (2, np.float64(0.8)),\n",
      "              (3, np.float64(0.8076923076923078)),\n",
      "              (4, np.float64(0.8307692307692308)),\n",
      "              (5, np.float64(0.823076923076923))]}\n",
      "\n",
      "Centralized metrics: {}\n",
      "Distributed metrics: {'accuracy': [(1, np.float64(0.8)), (2, np.float64(0.8)), (3, np.float64(0.8076923076923078)), (4, np.float64(0.8307692307692308)), (5, np.float64(0.823076923076923))]}\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Inspect History & Evaluate Global Model\n",
    "\n",
    "print(\"Simulation History:\")\n",
    "print(history)  # Should show loss, accuracy per round if metrics collected\n",
    "\n",
    "# If history.metrics_centralized or distributed available\n",
    "if hasattr(history, 'metrics_centralized'):\n",
    "    print(\"Centralized metrics:\", history.metrics_centralized)\n",
    "if hasattr(history, 'metrics_distributed'):\n",
    "    print(\"Distributed metrics:\", history.metrics_distributed)\n",
    "\n",
    "# To evaluate the final global model properly, we need the aggregated parameters.\n",
    "# For simplicity: re-create global model and assume last aggregated params (manual extract from strategy if needed).\n",
    "# Quick hack: Run evaluation on test set using a model trained centrally for comparison (or note round accuracies from logs)\n",
    "\n",
    "# From logs, look for lines like:\n",
    "# evaluate_round 5 aggregated results: {'accuracy': X.XX}\n",
    "# If you see them in output, note the last one (e.g., round 5 accuracy)\n",
    "\n",
    "# Bonus: Print client accuracies from logs if visible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
